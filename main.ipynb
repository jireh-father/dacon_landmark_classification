{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "- ubuntu 16.04\n",
    "- python 3.6.5\n",
    "- cuda 10.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 준비 \n",
    "- data.zip 다운로드\n",
    "- 현재 프로젝트 root경로를 기준으로 아래처럼 경로가 세팅되도록 압축을 풀어주세요.\n",
    "\n",
    "- 학습 이미지 경로 샘플\n",
    " - ./data/public/train/경기도/만안교/만안교_001.JPG\n",
    "\n",
    "- 테스트 이미지 경로 샘플\n",
    " - ./data/public/test/0/0b9jdr0e39.JPG\n",
    "\n",
    "- train.csv\n",
    " - ./data/public/train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 총 15개의 모델 학습 \n",
    "- efficientnet b0~b7\n",
    "- fishnet150, fishnet201\n",
    "- resnext\n",
    "- efficientnet b3, b3, b4, b7 with all training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습1\n",
    "- model: efficientnet-b0\n",
    "- arcface loss\n",
    "- multiple pooling concat(GeM,MAC,SPoC)\n",
    "- cutmix 0.5 probabiliy, beta 1.0\n",
    "- label smoothing: 0.1\n",
    "- augmentations: random crop, brightness, contrast, horizontal flip, shift, scale\n",
    "- input size: 216(h)x384(w)\n",
    "\n",
    "## 2개의 GPU로 학습시킬 경우\n",
    "CUDA_VISIBLE_DEVICE=**0,1** python main.py **--data_parallel** ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python main.py \\\n",
    "--train_dir=./data/public/train/ \\\n",
    "--optimizer=adamp \\\n",
    "--seed=1 \\\n",
    "--train \\\n",
    "--val \\\n",
    "--use_benchmark \\\n",
    "--train_batch_size=96 \\\n",
    "--val_batch_size=128 \\\n",
    "--log_step_interval=50 \\\n",
    "--model_name=arc_face,efficientnet-b0 \\\n",
    "--input_size=216,384 \\\n",
    "--scheduler=step \\\n",
    "--lr_restart_step=1 \\\n",
    "--train_pin_memory \\\n",
    "--val_pin_memory \\\n",
    "--num_classes=1049 \\\n",
    "--num_epochs=33 \\\n",
    "--num_workers=8 \\\n",
    "--label_file=data/public/train.csv \\\n",
    "--save_dir=work_landmark/cp_efb0 \\\n",
    "--log_dir=work_landmark/log_efb0 \\\n",
    "--transform_func_name=get_train_transforms_simple_bright_randomcrop \\\n",
    "--cutmix_prob=0.5 \\\n",
    "--beta=1.0 \\\n",
    "--label_smoothing \\\n",
    "--smoothing=0.1 \\\n",
    "--pooling=GeM,MAC,SPoC \\\n",
    "--pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습2\n",
    "- model: efficientnet-b1\n",
    "- cutmix 0.5 probabiliy, beta 1.0\n",
    "- label smoothing: 0.1\n",
    "- augmentations: random crop, horizontal flip\n",
    "- input size: 216(h)x384(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python main.py \\\n",
    "--train_dir=./data/public/train/ \\\n",
    "--optimizer=adamp \\\n",
    "--seed=1 \\\n",
    "--train \\\n",
    "--val \\\n",
    "--use_benchmark \\\n",
    "--train_batch_size=56 \\\n",
    "--val_batch_size=128 \\\n",
    "--log_step_interval=50 \\\n",
    "--model_name=efficientnet-b1 \\\n",
    "--input_size=216,384 \\\n",
    "--scheduler=step \\\n",
    "--lr_restart_step=1 \\\n",
    "--train_pin_memory \\\n",
    "--val_pin_memory \\\n",
    "--num_classes=1049 \\\n",
    "--num_epochs=25 \\\n",
    "--num_workers=8 \\\n",
    "--label_file=data/public/train.csv \\\n",
    "--save_dir=work_landmark/cp_efb1 \\\n",
    "--log_dir=work_landmark/log_efb1 \\\n",
    "--transform_func_name=get_train_transforms_simple_randomcrop \\\n",
    "--cutmix_prob=0.5 \\\n",
    "--beta=1.0 \\\n",
    "--label_smoothing \\\n",
    "--smoothing=0.1 \\\n",
    "--pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습3\n",
    "- model: efficientnet-b2\n",
    "- arcface loss\n",
    "- multiple pooling concat(GeM,MAC,SPoC)\n",
    "- label smoothing: 0.1\n",
    "- cutmix 0.5 probabiliy, beta 1.0\n",
    "- augmentations: random crop, brightness, contrast, flip, shift, scale\n",
    "- input size: 216(h)x384(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python main.py \\\n",
    "--train_dir=./data/public/train/ \\\n",
    "--optimizer=adamp \\\n",
    "--seed=1 \\\n",
    "--train \\\n",
    "--val \\\n",
    "--use_benchmark \\\n",
    "--train_batch_size=56 \\\n",
    "--val_batch_size=128 \\\n",
    "--log_step_interval=50 \\\n",
    "--model_name=arc_face,efficientnet-b2 \\\n",
    "--input_size=216,384 \\\n",
    "--scheduler=step \\\n",
    "--lr_restart_step=1 \\\n",
    "--train_pin_memory \\\n",
    "--val_pin_memory \\\n",
    "--num_classes=1049 \\\n",
    "--num_epochs=43 \\\n",
    "--num_workers=8 \\\n",
    "--label_file=data/public/train.csv \\\n",
    "--save_dir=work_landmark/cp_efb2 \\\n",
    "--log_dir=work_landmark/log_efb2 \\\n",
    "--transform_func_name=get_train_transforms_simple_bright_randomcrop \\\n",
    "--cutmix_prob=0.5 \\\n",
    "--beta=1.0 \\\n",
    "--label_smoothing \\\n",
    "--smoothing=0.1 \\\n",
    "--pooling=GeM,MAC,SPoC \\\n",
    "--pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습4\n",
    "- model: efficientnet-b3\n",
    "- arcface loss\n",
    "- multiple pooling concat(GeM,MAC,SPoC)\n",
    "- cutmix 0.5 probabiliy, beta 1.0\n",
    "- label smoothing: 0.1\n",
    "- augmentations: random crop, brightness, contrast, flip, shift, scale\n",
    "- input size: 216(h)x384(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python main.py \\\n",
    "--train_dir=./data/public/train/ \\\n",
    "--optimizer=adamp \\\n",
    "--seed=1 \\\n",
    "--train \\\n",
    "--val \\\n",
    "--use_benchmark \\\n",
    "--train_batch_size=52 \\\n",
    "--val_batch_size=128 \\\n",
    "--log_step_interval=50 \\\n",
    "--model_name=arc_face,efficientnet-b3 \\\n",
    "--input_size=216,384 \\\n",
    "--scheduler=step \\\n",
    "--lr_restart_step=1 \\\n",
    "--train_pin_memory \\\n",
    "--val_pin_memory \\\n",
    "--num_classes=1049 \\\n",
    "--num_epochs=41 \\\n",
    "--num_workers=8 \\\n",
    "--label_file=data/public/train.csv \\\n",
    "--save_dir=work_landmark/cp_efb3 \\\n",
    "--log_dir=work_landmark/log_efb3 \\\n",
    "--transform_func_name=get_train_transforms_simple_bright_randomcrop \\\n",
    "--cutmix_prob=0.5 \\\n",
    "--beta=1.0 \\\n",
    "--label_smoothing \\\n",
    "--smoothing=0.1 \\\n",
    "--pooling=GeM,MAC,SPoC \\\n",
    "--pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습5\n",
    "- model: efficientnet-b4\n",
    "- arcface loss\n",
    "- multiple pooling concat(GeM,MAC,SPoC)\n",
    "- cutmix 0.5 probabiliy, beta 1.0\n",
    "- label smoothing: 0.1\n",
    "- augmentations: random crop, brightness, contrast, flip, shift, scale\n",
    "- input size: 216(h)x384(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python main.py \\\n",
    "--train_dir=./data/public/train/ \\\n",
    "--optimizer=adamp \\\n",
    "--seed=1 \\\n",
    "--train \\\n",
    "--val \\\n",
    "--use_benchmark \\\n",
    "--train_batch_size=32 \\\n",
    "--val_batch_size=64 \\\n",
    "--log_step_interval=50 \\\n",
    "--model_name=arc_face,efficientnet-b4 \\\n",
    "--input_size=216,384 \\\n",
    "--scheduler=step \\\n",
    "--lr_restart_step=1 \\\n",
    "--train_pin_memory \\\n",
    "--val_pin_memory \\\n",
    "--num_classes=1049 \\\n",
    "--num_epochs=32 \\\n",
    "--num_workers=8 \\\n",
    "--label_file=data/public/train.csv \\\n",
    "--save_dir=work_landmark/cp_efb4 \\\n",
    "--log_dir=work_landmark/log_efb4 \\\n",
    "--transform_func_name=get_train_transforms_simple_bright_randomcrop \\\n",
    "--cutmix_prob=0.5 \\\n",
    "--beta=1.0 \\\n",
    "--label_smoothing \\\n",
    "--smoothing=0.1 \\\n",
    "--pooling=GeM,MAC,SPoC \\\n",
    "--pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습6\n",
    "- model: efficientnet-b5\n",
    "- arcface loss\n",
    "- multiple pooling concat(GeM,MAC,SPoC)\n",
    "- label smoothing: 0.1\n",
    "- cutmix 0.5 probabiliy, beta 1.0\n",
    "- augmentations: random crop, brightness, contrast, flip, shift, scale\n",
    "- input size: 216(h)x384(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python main.py \\\n",
    "--train_dir=./data/public/train/ \\\n",
    "--optimizer=adamp \\\n",
    "--seed=1 \\\n",
    "--train \\\n",
    "--val \\\n",
    "--use_benchmark \\\n",
    "--train_batch_size=56 \\\n",
    "--val_batch_size=128 \\\n",
    "--log_step_interval=50 \\\n",
    "--model_name=arc_face,efficientnet-b5 \\\n",
    "--input_size=216,384 \\\n",
    "--scheduler=step \\\n",
    "--lr_restart_step=1 \\\n",
    "--train_pin_memory \\\n",
    "--val_pin_memory \\\n",
    "--num_classes=1049 \\\n",
    "--num_epochs=45 \\\n",
    "--num_workers=8 \\\n",
    "--label_file=data/public/train.csv \\\n",
    "--save_dir=work_landmark/cp_efb5 \\\n",
    "--log_dir=work_landmark/log_efb5 \\\n",
    "--transform_func_name=get_train_transforms_simple_bright_randomcrop \\\n",
    "--cutmix_prob=0.5 \\\n",
    "--beta=1.0 \\\n",
    "--label_smoothing \\\n",
    "--smoothing=0.1 \\\n",
    "--pooling=GeM,MAC,SPoC \\\n",
    "--pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습7\n",
    "- model: efficientnet-b6\n",
    "- cutmix 0.5 probabiliy, beta 1.0\n",
    "- label smoothing: 0.1\n",
    "- augmentations: random crop, horizontal flip\n",
    "- input size: 216(h)x384(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python main.py \\\n",
    "--train_dir=./data/public/train/ \\\n",
    "--optimizer=adamp \\\n",
    "--seed=1 \\\n",
    "--train \\\n",
    "--val \\\n",
    "--use_benchmark \\\n",
    "--train_batch_size=32 \\\n",
    "--val_batch_size=64 \\\n",
    "--log_step_interval=50 \\\n",
    "--model_name=efficientnet-b6 \\\n",
    "--input_size=216,384 \\\n",
    "--scheduler=step \\\n",
    "--lr_restart_step=1 \\\n",
    "--train_pin_memory \\\n",
    "--val_pin_memory \\\n",
    "--num_classes=1049 \\\n",
    "--num_epochs=25 \\\n",
    "--num_workers=8 \\\n",
    "--label_file=data/public/train.csv \\\n",
    "--save_dir=work_landmark/cp_efb6 \\\n",
    "--log_dir=work_landmark/log_efb6 \\\n",
    "--transform_func_name=get_train_transforms_simple_randomcrop \\\n",
    "--cutmix_prob=0.5 \\\n",
    "--beta=1.0 \\\n",
    "--label_smoothing \\\n",
    "--smoothing=0.1 \\\n",
    "--pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습8\n",
    "- model: efficientnet-b7\n",
    "- cutmix 0.5 probabiliy, beta 1.0\n",
    "- label smoothing: 0.1\n",
    "- augmentations: random crop, horizontal flip\n",
    "- input size: 216(h)x384(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python main.py \\\n",
    "--train_dir=./data/public/train/ \\\n",
    "--optimizer=adamp \\\n",
    "--seed=1 \\\n",
    "--train \\\n",
    "--val \\\n",
    "--use_benchmark \\\n",
    "--train_batch_size=32 \\\n",
    "--val_batch_size=64 \\\n",
    "--log_step_interval=50 \\\n",
    "--model_name=efficientnet-b7 \\\n",
    "--input_size=216,384 \\\n",
    "--scheduler=step \\\n",
    "--lr_restart_step=1 \\\n",
    "--train_pin_memory \\\n",
    "--val_pin_memory \\\n",
    "--num_classes=1049 \\\n",
    "--num_epochs=29 \\\n",
    "--num_workers=8 \\\n",
    "--label_file=data/public/train.csv \\\n",
    "--save_dir=work_landmark/cp_efb7 \\\n",
    "--log_dir=work_landmark/log_efb7 \\\n",
    "--transform_func_name=get_train_transforms_simple_randomcrop \\\n",
    "--cutmix_prob=0.5 \\\n",
    "--beta=1.0 \\\n",
    "--label_smoothing \\\n",
    "--smoothing=0.1 \\\n",
    "--pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습9\n",
    "- model: fishnet150\n",
    "- cutmix 0.5 probabiliy, beta 1.0\n",
    "- label smoothing: 0.1\n",
    "- augmentations: random crop, brightness, contrast, flip, shift, scale\n",
    "- input size: 224(h)x224(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python main.py \\\n",
    "--train_dir=./data/public/train/ \\\n",
    "--optimizer=adamp \\\n",
    "--seed=1 \\\n",
    "--train \\\n",
    "--val \\\n",
    "--use_benchmark \\\n",
    "--train_batch_size=56 \\\n",
    "--val_batch_size=128 \\\n",
    "--log_step_interval=50 \\\n",
    "--model_name=fishnet150 \\\n",
    "--input_size=224 \\\n",
    "--scheduler=step \\\n",
    "--lr_restart_step=1 \\\n",
    "--train_pin_memory \\\n",
    "--val_pin_memory \\\n",
    "--num_classes=1049 \\\n",
    "--num_epochs=31 \\\n",
    "--num_workers=8 \\\n",
    "--label_file=data/public/train.csv \\\n",
    "--save_dir=work_landmark/cp_fishnet150 \\\n",
    "--log_dir=work_landmark/log_fishnet150 \\\n",
    "--transform_func_name=get_train_transforms_simple_randomcrop \\\n",
    "--cutmix_prob=0.5 \\\n",
    "--beta=1.0 \\\n",
    "--label_smoothing \\\n",
    "--smoothing=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습10\n",
    "- model: fishnet150\n",
    "- cutmix 0.5 probabiliy, beta 1.0\n",
    "- label smoothing: 0.1\n",
    "- augmentations: random crop, brightness, contrast, flip, shift, scale\n",
    "- input size: 224(h)x224(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python main.py \\\n",
    "--train_dir=./data/public/train/ \\\n",
    "--optimizer=adamp \\\n",
    "--seed=1 \\\n",
    "--train \\\n",
    "--val \\\n",
    "--use_benchmark \\\n",
    "--train_batch_size=56 \\\n",
    "--val_batch_size=128 \\\n",
    "--log_step_interval=50 \\\n",
    "--model_name=fishnet201 \\\n",
    "--input_size=224 \\\n",
    "--scheduler=step \\\n",
    "--lr_restart_step=1 \\\n",
    "--train_pin_memory \\\n",
    "--val_pin_memory \\\n",
    "--num_classes=1049 \\\n",
    "--num_epochs=24 \\\n",
    "--num_workers=8 \\\n",
    "--label_file=data/public/train.csv \\\n",
    "--save_dir=work_landmark/cp_fishnet201 \\\n",
    "--log_dir=work_landmark/log_fishnet201 \\\n",
    "--transform_func_name=get_train_transforms_simple_randomcrop \\\n",
    "--cutmix_prob=0.5 \\\n",
    "--beta=1.0 \\\n",
    "--label_smoothing \\\n",
    "--smoothing=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습11\n",
    "- model: resnext101_32x8d\n",
    "- augmentations: flip\n",
    "- input size: 216(h)x384(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python main.py \\\n",
    "--train_dir=./data/public/train/ \\\n",
    "--optimizer=adamp \\\n",
    "--seed=1 \\\n",
    "--train \\\n",
    "--val \\\n",
    "--use_benchmark \\\n",
    "--train_batch_size=64 \\\n",
    "--val_batch_size=128 \\\n",
    "--log_step_interval=50 \\\n",
    "--model_name=resnext101_32x8d \\\n",
    "--input_size=216,384 \\\n",
    "--scheduler=step \\\n",
    "--lr_restart_step=1 \\\n",
    "--train_pin_memory \\\n",
    "--val_pin_memory \\\n",
    "--num_classes=1049 \\\n",
    "--num_epochs=17 \\\n",
    "--num_workers=8 \\\n",
    "--label_file=data/public/train.csv \\\n",
    "--save_dir=work_landmark/cp_resnext \\\n",
    "--log_dir=work_landmark/log_resnext \\\n",
    "--transform_func_name=get_train_transforms_simple \\\n",
    "--pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습12\n",
    "- model: efficientnet-b7\n",
    "- cutmix 0.5 probabiliy, beta 1.0\n",
    "- label smoothing: 0.1\n",
    "- augmentations: random crop, brightness, contrast, flip, shift, scale\n",
    "- input size: 356(h)x632(w)\n",
    "- trained with all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python main.py \\\n",
    "--train_dir=./data/public/train/ \\\n",
    "--optimizer=adamp \\\n",
    "--seed=1 \\\n",
    "--train \\\n",
    "--val \\\n",
    "--use_benchmark \\\n",
    "--train_batch_size=4 \\\n",
    "--val_batch_size=8 \\\n",
    "--log_step_interval=50 \\\n",
    "--model_name=efficientnet-b7 \\\n",
    "--input_size=356,632 \\\n",
    "--scheduler=step \\\n",
    "--lr_restart_step=1 \\\n",
    "--train_pin_memory \\\n",
    "--val_pin_memory \\\n",
    "--num_classes=1049 \\\n",
    "--num_epochs=21 \\\n",
    "--num_workers=8 \\\n",
    "--label_file=data/public/train.csv \\\n",
    "--save_dir=work_landmark/cp_alldata_efb7 \\\n",
    "--log_dir=work_landmark/log_alldata_efb7 \\\n",
    "--transform_func_name=get_train_transforms_simple_bright_randomcrop \\\n",
    "--cutmix_prob=0.5 \\\n",
    "--beta=1.0 \\\n",
    "--label_smoothing \\\n",
    "--smoothing=0.1 \\\n",
    "--pretrained \\\n",
    "--use_all_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습13\n",
    "- model: efficientnet-b3\n",
    "- arcface loss\n",
    "- multiple pooling concat(GeM,MAC,SPoC)\n",
    "- cutmix 0.5 probabiliy, beta 1.0\n",
    "- augmentations: random crop, brightness, contrast, flip, shift, scale\n",
    "- input size: 216(h)x384(w)\n",
    "- trained with all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python main.py \\\n",
    "--train_dir=./data/public/train/ \\\n",
    "--optimizer=adamp \\\n",
    "--seed=1 \\\n",
    "--train \\\n",
    "--val \\\n",
    "--use_benchmark \\\n",
    "--train_batch_size=52 \\\n",
    "--val_batch_size=128 \\\n",
    "--log_step_interval=50 \\\n",
    "--model_name=arc_face,efficientnet-b3 \\\n",
    "--input_size=216,384 \\\n",
    "--scheduler=step \\\n",
    "--lr_restart_step=1 \\\n",
    "--train_pin_memory \\\n",
    "--val_pin_memory \\\n",
    "--num_classes=1049 \\\n",
    "--num_epochs=30 \\\n",
    "--num_workers=8 \\\n",
    "--label_file=data/public/train.csv \\\n",
    "--save_dir=work_landmark/cp_alldata_efb3_arcface \\\n",
    "--log_dir=work_landmark/log_alldata_efb3_arcface \\\n",
    "--transform_func_name=get_train_transforms_simple_bright_randomcrop \\\n",
    "--cutmix_prob=0.5 \\\n",
    "--beta=1.0 \\\n",
    "--label_smoothing \\\n",
    "--smoothing=0.1 \\\n",
    "--pooling=GeM,MAC,SPoC \\\n",
    "--pretrained \\\n",
    "--use_all_train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습14\n",
    "- model: efficientnet-b3\n",
    "- cutmix 0.5 probabiliy, beta 1.0\n",
    "- label smoothing: 0.1\n",
    "- augmentations: random crop, brightness, contrast, flip, shift, scale\n",
    "- input size: 216(h)x384(w)\n",
    "- trained with all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python main.py \\\n",
    "--train_dir=./data/public/train/ \\\n",
    "--optimizer=adamp \\\n",
    "--seed=1 \\\n",
    "--train \\\n",
    "--val \\\n",
    "--use_benchmark \\\n",
    "--train_batch_size=52 \\\n",
    "--val_batch_size=128 \\\n",
    "--log_step_interval=50 \\\n",
    "--model_name=efficientnet-b3 \\\n",
    "--input_size=216,384 \\\n",
    "--scheduler=step \\\n",
    "--lr_restart_step=1 \\\n",
    "--train_pin_memory \\\n",
    "--val_pin_memory \\\n",
    "--num_classes=1049 \\\n",
    "--num_epochs=42 \\\n",
    "--num_workers=8 \\\n",
    "--label_file=data/public/train.csv \\\n",
    "--save_dir=work_landmark/cp_alldata_efb3 \\\n",
    "--log_dir=work_landmark/log_alldata_efb3 \\\n",
    "--transform_func_name=get_train_transforms_simple_bright_randomcrop \\\n",
    "--cutmix_prob=0.5 \\\n",
    "--beta=1.0 \\\n",
    "--label_smoothing \\\n",
    "--smoothing=0.1 \\\n",
    "--pretrained \\\n",
    "--use_all_train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습15\n",
    "- model: efficientnet-b4\n",
    "- cutmix 0.5 probabiliy, beta 1.0\n",
    "- label smoothing: 0.1\n",
    "- augmentations: random crop, brightness, contrast, flip, shift, scale\n",
    "- input size: 216(h)x384(w)\n",
    "- trained with all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python main.py \\\n",
    "--train_dir=./data/public/train/ \\\n",
    "--optimizer=adamp \\\n",
    "--seed=1 \\\n",
    "--train \\\n",
    "--val \\\n",
    "--use_benchmark \\\n",
    "--train_batch_size=52 \\\n",
    "--val_batch_size=128 \\\n",
    "--log_step_interval=50 \\\n",
    "--model_name=efficientnet-b4 \\\n",
    "--input_size=216,384 \\\n",
    "--scheduler=step \\\n",
    "--lr_restart_step=1 \\\n",
    "--train_pin_memory \\\n",
    "--val_pin_memory \\\n",
    "--num_classes=1049 \\\n",
    "--num_epochs=16 \\\n",
    "--num_workers=8 \\\n",
    "--label_file=data/public/train.csv \\\n",
    "--save_dir=work_landmark/cp_alldata_efb4 \\\n",
    "--log_dir=work_landmark/log_alldata_efb4 \\\n",
    "--transform_func_name=get_train_transforms_simple_bright_randomcrop \\\n",
    "--cutmix_prob=0.5 \\\n",
    "--beta=1.0 \\\n",
    "--label_smoothing \\\n",
    "--smoothing=0.1 \\\n",
    "--pretrained \\\n",
    "--use_all_train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signle Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://font-recognizer-bucket.s3.us-east-2.amazonaws.com/resource/kaggle/efb3_arcface_alldata_e30.pth\n",
    "    \n",
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python main.py \\\n",
    "--checkpoint_path=./efb3_arcface_alldata_e30.pth \\\n",
    "--train_dir=./data/public/train/ \\\n",
    "--seed=1 \\\n",
    "--val \\\n",
    "--use_benchmark \\\n",
    "--val_batch_size=256 \\\n",
    "--log_step_interval=50 \\\n",
    "--model_name=arc_face,efficientnet-b3 \\\n",
    "--input_size=216,384 \\\n",
    "--val_pin_memory \\\n",
    "--num_classes=1049 \\\n",
    "--num_workers=8 \\\n",
    "--label_file=data/public/train.csv \\\n",
    "--pooling=GeM,MAC,SPoC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Model Submission\n",
    "- efficientnet-b3\n",
    "- trained with all dataset\n",
    "- arcface\n",
    "- pooling concat (GeM,MAC,SPoC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://font-recognizer-bucket.s3.us-east-2.amazonaws.com/resource/kaggle/efb3_arcface_alldata_e30.pth\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python submit.py \\\n",
    "--output_csv_path=work_landmark/submission_single_model.csv \\\n",
    "--checkpoint_path=./efb3_arcface_alldata_e30.pth \\\n",
    "--test_dir=./data/public/test/ \\\n",
    "--model_name=arc_face,efficientnet-b3 \\\n",
    "--num_workers=8 \\\n",
    "--num_classes=1049 \\\n",
    "--batch_size=256 \\\n",
    "--input_size=216,384 \\\n",
    "--seed=1 \\\n",
    "--pooling=GeM,MAC,SPoC \\\n",
    "--use_benchmark\n",
    "\n",
    "!echo \"submission top 3 lines.\"\n",
    "\n",
    "!head -n 3 work_landmark/submission_single_model.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Validation\n",
    "efficientnet-b3, b4 두 모델 ensemble 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://font-recognizer-bucket.s3.us-east-2.amazonaws.com/resource/kaggle/efb3_arcface_alldata_e30.pth\n",
    "!wget -nc https://font-recognizer-bucket.s3.us-east-2.amazonaws.com/resource/kaggle/efb4_arcface_epoch_32.pth\n",
    "    \n",
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python ensemble_submit.py \\\n",
    "--checkpoint_paths=./efb3_arcface_alldata_e30.pth,efb4_arcface_epoch_32.pth \\\n",
    "--model_names=arc_face,efficientnet-b3:arc_face,efficientnet-b4 \\\n",
    "--input_sizes=216x384,216x384 \\\n",
    "--poolings=GeM,MAC,SPoC:GeM,MAC,SPoC \\\n",
    "--weights=0.6,0.4 \\\n",
    "--label_file=data/public/train.csv \\\n",
    "--image_dir=./data/public/train \\\n",
    "--num_classes=1049 \\\n",
    "--batch_size=256 \\\n",
    "-w=8 \\\n",
    "--eval \\\n",
    "--seed=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://font-recognizer-bucket.s3.us-east-2.amazonaws.com/resource/kaggle/efb3_arcface_alldata_e30.pth\n",
    "!wget -nc https://font-recognizer-bucket.s3.us-east-2.amazonaws.com/resource/kaggle/efb4_arcface_epoch_32.pth\n",
    "    \n",
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python ensemble_submit.py \\\n",
    "--checkpoint_paths=./efb3_arcface_alldata_e30.pth,efb4_arcface_epoch_32.pth \\\n",
    "--model_names=arc_face,efficientnet-b3:arc_face,efficientnet-b4 \\\n",
    "--input_sizes=216x384,216x384 \\\n",
    "--poolings=GeM,MAC,SPoC:GeM,MAC,SPoC \\\n",
    "--weights=0.6,0.4 \\\n",
    "--test_dir=./data/public/test \\\n",
    "--num_classes=1049 \\\n",
    "--batch_size=256 \\\n",
    "-w=8 \\\n",
    "--test \\\n",
    "--csv=./work_landmark/submission/ensemble_submision.csv \\\n",
    "--seed=1\n",
    "\n",
    "!echo \"\"\n",
    "!echo \"head 3 lines of submission file\"\n",
    "!head -n 3 ./work_landmark/submission/ensemble_submision.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Submission (15models ensemble submission)\n",
    "- 위에 15가지 모델이 모두 학습된 모델 파일이 정확한 경로에 저장되어 있어야만 동작합니다.\n",
    "\n",
    "- 앙상블할 모델 순서를 정렬하면 아래 순서로 정렬되기 때문에 정렬된 순서데로 모델의 가중치나 하이퍼 파라미터들을 잘 세팅해야 합니다.\n",
    "- 모델 순서: 4 efficient models(trained with all dataset, efb3, efb3_arc_face, efb4, efb7), 8 efficientnet models(b0 to b8), 2 fishnet models, 1 resnext model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가상으로 동작하게 하도록 하기 위해 한 모델을 다운로드 하여 모든 디렉토리에 저장하고 실행되도록  하는 코드입니다.\n",
    "!wget -nc https://font-recognizer-bucket.s3.us-east-2.amazonaws.com/resource/kaggle/efb3_arcface_alldata_e30.pth\n",
    "import shutil\n",
    "import os\n",
    "path_list  = ['cp_efb0','cp_efb1','cp_efb2','cp_efb3','cp_efb4','cp_efb5','cp_efb6','cp_efb7','cp_alldata_efb3','cp_alldata_efb3_arcface','cp_alldata_efb4','cp_alldata_efb7','cp_fishnet150','cp_fishnet201','cp_resnext']\n",
    "model_path = \"efb3_arcface_alldata_e30.pth\"\n",
    "\n",
    "for path in path_list:\n",
    "    os.makedirs(os.path.join('work_landmark', path), exist_ok=True)\n",
    "    shutil.copy(model_path, os.path.join('work_landmark', path, \"val_best.pth\"))\n",
    "    print(path, \"copied\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정상적인 결과를 보기위해서는 15개 모델을 모두 학습후에 진행해야 합니다.\n",
    "# 정확한 확인을 위해서는 --not_strict 인자를 제거해야 합니다.(가상으로 동작하게 하기 위한 인자)\n",
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python ensemble_submit.py \\\n",
    "--checkpoint_paths=./work_landmark/cp_*/val_best.pth \\\n",
    "--model_names=efficientnet-b3:arc_face,efficientnet-b3:efficientnet-b4:efficientnet-b7:arc_face,efficientnet-b0:efficientnet-b1:arc_face,efficientnet-b2:arc_face,efficientnet-b3:arc_fcae,efficientnet-b4:arc_face,efficientnet-b5:efficientnet-b6:efficientnet-b7:fishnet150:fishnet201:resnext101_32x8d \\\n",
    "--input_sizes=216x384,216x384,216x384,356x632,216x384,216x384,216x384,216x384,216x384,216x384,216x384,216x384,224x224,224x224,216x384 \\\n",
    "--poolings=GAP:GeM,MAC,SPoC:GAP:GAP:GeM,MAC,SPoC:GAP:GeM,MAC,SPoC:GeM,MAC,SPoC:GeM,MAC,SPoC:GeM,MAC,SPoC:GAP:GAP:GAP:GAP:GAP \\\n",
    "--weights=0.2,0.2,0.2,0.2,0.1,0.1,0.1,0.5,0.2,0.1,0.1,0.6,0.08,0.08,0.05 \\\n",
    "--test_dir=./data/public/test \\\n",
    "--num_classes=1049 \\\n",
    "--batch_size=256 \\\n",
    "-w=8 \\\n",
    "--test \\\n",
    "--use_glob \\\n",
    "--csv=./work_landmark/submission/15models_ensemble_submision.csv \\\n",
    "--seed=1 \\\n",
    "--not_strict\n",
    "                                                                                                                \n",
    "!head -n 3 ./work_landmark/submission/15models_ensemble_submision.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon_landmark2",
   "language": "python",
   "name": "dacon_landmark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
